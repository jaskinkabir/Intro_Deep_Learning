\documentclass{article}
%\usepackage[margin=1in]{geometry}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{titling}
\usepackage{enumitem}
\usepackage{makecell}
\usepackage{minted}
\usepackage{url}
\usepackage{tabularx}
\usepackage{graphicx}
\renewcommand\maketitlehooka{\null\mbox{}\vfill}
\renewcommand\maketitlehookd{\vfill\null}

\begin{document}
\input{title.tex}

\section{Problem 1: Character Prediction Small Dataset}

\begin{enumerate}[label=1\alph*. ]
    \item \textit{Training Curves}
    \begin{figure}[htb]
        \setkeys{Gin}{width=\linewidth}
        \setlength\tabcolsep{2pt}
        \begin{tabularx}{\textwidth}{XXX}
          \includegraphics{images_p1/RNN_10_training_new.png} &
          \includegraphics{images_p1/RNN_20_training_new.png} &
          \includegraphics{images_p1/RNN_30_training_new.png}   \\
          \includegraphics{images_p1/LSTM_10_training_new.png} &
          \includegraphics{images_p1/LSTM_20_training_new.png} &
          \includegraphics{images_p1/LSTM_30_training_new.png}   \\
          \includegraphics{images_p1/GRU_10_training_new.png} &
          \includegraphics{images_p1/GRU_20_training_new.png} &
          \includegraphics{images_p1/GRU_30_training_new.png}
        \end{tabularx}
        \caption{Problem 1 Training Curves}
        \label{fig:p1}
      \end{figure}
      \newpage
    \item \textit{Results Comparison}
    \begin{table}[h]
        \centering
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|}
        %\begin{tabular}{|l|r|r|r|r|}
            \hline
            \textbf{Model} & \textbf{Parameter Count} & \textbf{Training Time (s)} & \textbf{Overfit (\%)} & \textbf{Accuracy (\%)} \\
            \hline
            \textbf{RNN-10}  & 44846  & 1.93  & 389.68  & 49.58 \\
            \textbf{RNN-20}  & 44846  & 3.65  & 185.97  & 51.05 \\
            \textbf{RNN-30}  & 44846  & 5.24  & 235.41  & 48.31 \\
            \hline
            \textbf{LSTM-10} & 143918 & 5.79  & 253.80  & 48.95 \\
            \textbf{LSTM-20} & 143918 & 11.21 & 381.00  & 53.16 \\
            \textbf{LSTM-30} & 143918 & 18.23 & 399.18  & 50.00 \\
            \hline
            \textbf{GRU-10}  & 110894 & 5.30  & 329.01  & 51.89 \\
            \textbf{GRU-20}  & 110894 & 9.88  & 347.95  & 54.01 \\
            \textbf{GRU-30}  & 110894 & 15.41 & 460.00  & 50.85 \\
            \hline
        \end{tabular}
        \caption{Problem 1 Data Comparison}
        \label{tab:p1}
    \end{table}
    \item \textit{Discussion} 
    \begin{itemize}
        \item Parameter Count
            
            The parameter count of the LSTM network was more
            than triple that of the basic RNN network, and
            the GRU was almost halfway between the two. This
            is to be expected, as the LSTM adds significant
            complexity to the base RNN architecture, and the
            GRU reduces that complexity. This complexity
            comes from the number of gates in each
            architecture. 
        \item Training Time
        
            The RNN was the quickest to train, followed by
            the GRU and then the LSTM. Training time seemed
            to increase linearly with sequence length for
            all architectures.
        \item Effect of Sequence Length

            The sequence length of 10 was too short for the
            models to have enough relevant information,
            while the length of 30 was too difficult for the
            models to learn. The sequence length of 20 was
            the best compromise between the two. 

        \item Overfitting
        
            For the best sequence length of 20, the RNN had
            the lowest overfit and the LSTM the highest. This
            is likely a result of the difference in
            complexity between the architectures. The most
            complex model, the LSTM, had the highest
            overfit.

            Interestingly, for the sequence length of 10,
            the RNN the highest overfit while the LSTM had
            the lowest. This could be due to the RNN not
            having enough information to memorize the
            training data, while the LSTM was able to
            memorize more from the shorter sequences.

            For the sequence length of 30, the GRU had the
            highest overfit and the RNN the lowest. As the
            GRU was the most effective at generalizing from
            the training data, it makes sense that it would
            also overfit the most
        
        \item Accuracy
        
            Across all sequence lengths, the GRU was the
            most accurate and the RNN the least. The LSTM
            was in the middle. This is likely due to the
            complexity of the LSTM and the simplicity of the
            RNN. The GRU is a good compromise between the
            two, which is why it performed the best.

    
    \end{itemize}

\end{enumerate}
\newpage
\section{Problem 2: Shakespeare Character Prediction}
\begin{enumerate}[label=1\alph*. ]
    \item \textit{Training Curves}
    \begin{figure}[htb]
        \setkeys{Gin}{width=\linewidth}
        \setlength\tabcolsep{0.5pt}
        \renewcommand{\arraystretch}{0}
        \begin{tabularx}{\textwidth}{XXX}
          \includegraphics{images/LSTM-20_training_new.png} &
          \includegraphics{images/LSTM-30_training_new.png} &
          \includegraphics{images/LSTM-50_training_new.png} \\
          \includegraphics{images/LSTM-Adjusted-20_training_new.png} &
          \includegraphics{images/LSTM-Adjusted-30_training_new.png} &
          \includegraphics{images/LSTM-Adjusted-50_training_new.png} \\
          \includegraphics{images/GRU-20_training_new.png} &
          \includegraphics{images/GRU-30_training_new.png} &
          \includegraphics{images/GRU-50_training_new.png} \\
          \includegraphics{images/GRU-Adjusted-20_training_new.png} &
          \includegraphics{images/GRU-Adjusted-30_training_new.png} &
          \includegraphics{images/GRU-Adjusted-50_training_new.png}
        \end{tabularx}
        \caption{Problem 2 Training Curves}
        \label{fig:p2}
      \end{figure}
      \newpage
    \item \textit{Results Comparison}
    \begin{table}[h]
        \centering
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|}
        %\begin{tabular}{|l|r|r|r|r|}
            \hline
            \textbf{Model} & \textbf{Parameter Count} & \textbf{Training Time (s)} & \textbf{Inference Time (s)} & \textbf{Overfit (\%)} & \textbf{Accuracy (\%)} \\
            \hline
            \textbf{LSTM-20}  & 148801   & 346.11  & 3.83  & 56.62 \\ %done
            \textbf{LSTM-30}  & 44846  & 3.65  & 185.97  & 51.05 \\
            \textbf{LSTM-50}  & 44846  & 5.24  & 235.41  & 48.31 \\
            \hline
            \textbf{LSTM-Adjusted-20} & 143918 & 5.79  & 253.80  & 48.95 \\
            \textbf{LSTM-Adjusted-30} & 143918 & 11.21 & 381.00  & 53.16 \\
            \textbf{LSTM-Adjusted-50} & 143918 & 18.23 & 399.18  & 50.00 \\
            \hline
            \textbf{GRU-20}  & 115777  & 5.30  & 329.01  & 51.89 \\
            \textbf{GRU-30}  & 110894 & 9.88  & 347.95  & 54.01 \\
            \textbf{GRU-50}  & 110894 & 15.41 & 460.00  & 50.85 \\
            \hline
            \textbf{GRU-Adjusted-20}  & 110894 & 5.30  & 329.01  & 51.89 \\
            \textbf{GRU-Adjusted-30}  & 110894 & 9.88  & 347.95  & 54.01 \\
            \textbf{GRU-Adjusted-50}  & 110894 & 15.41 & 460.00  & 50.85 \\
            \hline
        \end{tabular}
        \caption{Problem 2 Data Comparison}
        \label{tab:p2}
    \end{table}
    \item \textit{Discussion} 
    \begin{itemize}
        \item Hyperparameter and Architecture Modifications
            To improve the LSTM's performance, the sequence
            length was reduced to 100 and two dense layers
            with batch normalization and dropout were added
            to the end of the model. These layers had 128
            and 64 neurons. The GRU was also modified in the
            same way, but the dense layers both had 256
            neurons. Additionally, because of the dropout
            layers, the learning rate was increased tenfold.
            These same modifications were made for all
            sequence lengths.

        \item Parameter Count
            
            The LSTM had more parameters than the GRU
            because it is the more complex architecture.
            However, when the models were adjusted to
            improve their performance, the LSTM had fewer
            parameters even after the additional layers
            because the reduction of sequence length was
            more significant for the LSTM. Additionally, the
            GRU's dense layers are 4 and 2 times larger than
            the LSTM's, respectively, which caused its
            adjusted parameter count to be the highest of
            the 4 models.
        \item Training Time

            Sequence length did not have a significant
            effect on training time. However, the GRU was
            significantly faster to train than the LSTM.
            Because the adjustments to the GRU model adds
            complexity, it took longer to train than the
            base model, whereas the adjusted LSTM model was
            faster to train than the base model.
            
        \item Inference Time
        
            Average inference time was on the order of
            nanoseconds for each model. This is likely due
            to the small size of the models and the
            simplicity of the task. The recorded data shows
            fluctuations between the models, but these are
            likely due to inaccuracies in recording
            inference time when all samples in the batch are
            computed in parallel.

        \item Overfitting
        
            For the best sequence length of 20, the RNN had
            the lowest overfit and the LSTM the highest. This
            is likely a result of the difference in
            complexity between the architectures. The most
            complex model, the LSTM, had the highest
            overfit.

            Interestingly, for the sequence length of 10,
            the RNN the highest overfit while the LSTM had
            the lowest. This could be due to the RNN not
            having enough information to memorize the
            training data, while the LSTM was able to
            memorize more from the shorter sequences.

            For the sequence length of 30, the GRU had the
            highest overfit and the RNN the lowest. As the
            GRU was the most effective at generalizing from
            the training data, it makes sense that it would
            also overfit the most
        
        \item Accuracy
        
            Across all sequence lengths, the GRU was the
            most accurate and the RNN the least. The LSTM
            was in the middle. This is likely due to the
            complexity of the LSTM and the simplicity of the
            RNN. The GRU is a good compromise between the
            two, which is why it performed the best.

    
    \end{itemize}

\end{enumerate}


\end{document}